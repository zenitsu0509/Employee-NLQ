# NLP Query Engine for Employee Data

This project delivers a full-stack AI-powered query system that can ingest employee databases and unstructured documents, automatically discover schemas, and serve natural language queries with production-ready optimizations.

## Project Overview

- **Backend**: FastAPI service providing ingestion, schema discovery, and query endpoints
- **Frontend**: React application for database configuration, document uploads, query interface, and analytics
- **Document Processing**: Multi-format ingestion with adaptive chunking and embedding generation
- **Query Engine**: Unified SQL and semantic retrieval with caching, optimization, and monitoring hooks

## Screenshot

![App UI](sample-data/image.png)

## Quick Start

### Prerequisites

- Python 3.11+ 
- Node.js 18+
- PostgreSQL (optional, SQLite works for testing)

### Backend Setup

1. **Create virtual environment and install dependencies:**

```bash
cd backend
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
pip install -r ../requirements.txt
```

1. **Run the FastAPI server:**

```bash
uvicorn backend.main:app --reload --host 0.0.0.0 --port 8000
```

1. **Test the API:**

```bash
curl http://localhost:8000/health
```

### Frontend Setup

1. **Install Node.js dependencies:**

```bash
cd frontend
npm install
```

1. **Start the development server:**

```bash
npm run dev
```

1. **Access the web interface:**

Open <http://localhost:5173> in your browser

### Docker Setup (Alternative)

1. **Run with Docker Compose:**

```bash
docker-compose up --build
```

This starts:

- Backend API: <http://localhost:8000>
- Frontend UI: <http://localhost:5173>
- PostgreSQL: localhost:5432
- Redis: localhost:6379

## Usage Examples

### 1. Connect to Database

```bash
curl -X POST http://localhost:8000/api/ingest/database \
  -H "Content-Type: application/json" \
  -d '{"connection_string": "postgresql+psycopg://user:password@localhost:5432/employees"}'
```

### 2. Upload Documents

```bash
curl -X POST http://localhost:8000/api/ingest/documents \
  -F "files=@resume.pdf" \
  -F "files=@handbook.docx" \
  -F "connection_string=postgresql+psycopg://user:password@localhost:5432/employees"
```

### 3. Query Your Data

```bash
curl -X POST http://localhost:8000/api/query \
  -H "Content-Type: application/json" \
  -d '{"query": "How many employees hired this year?", "top_k": 5}'
```

### 4. Modify Data (DML via natural language)

The query engine can also perform safe UPDATE/INSERT/DELETE operations generated by the LLM. The system avoids adding `LIMIT` to DML and commits the transaction if successful.

```bash
curl -X POST http://localhost:8000/api/query \
  -H "Content-Type: application/json" \
  -d '{
    "connection_string": "postgresql+psycopg://user:password@localhost:5432/employees",
    "query": "increase the salary of hr department by 10 percent"
  }'
```

Response example:

```json
{
  "results": [{"affected_rows": 3, "status": "success"}],
  "query_type": "sql",
  "metrics": {"response_ms": 120.5, "cache_hit": false}
}
```

Note: Always verify the result (affected_rows) and consider running within a transaction against non-production databases.

### 5. Optional: List ingestion jobs

If you uploaded documents and lost the job id, you can list current jobs:

```bash
curl -s http://localhost:8000/api/ingest/jobs
```

## Testing

Run the backend test suite:

```bash
cd backend
python -m pytest tests/ -v
```

## Configuration

Edit `config.yml` to customize:

- Database connection pooling
- Embedding model settings
- Cache configuration
- Logging levels

Notes:

- When using PostgreSQL with SQLAlchemy 2.x, prefer the psycopg v3 driver by specifying `postgresql+psycopg://...` in the connection string. This avoids requiring `psycopg2`.
- If running the backend inside Docker Compose, your connection string host should be the service name:
  - `postgresql+psycopg://user:password@postgres:5432/employees`
  If running the backend locally against Dockerized Postgres on your machine, use:
  - `postgresql+psycopg://user:password@localhost:5432/employees`

### Groq (LLM) configuration

This project can generate SQL with an LLM (Llama via Groq) for robust natural language understanding, including JOINs and DML. Configure your key in `config.yml`:

```yaml
groq:
  api_key: "<YOUR_GROQ_API_KEY>"
  model: "llama-3.1-8b-instant"
```

Security tip: Prefer setting `GROQ_API_KEY` via environment variable or secrets management in production.

## Architecture

### Backend Structure

```text
backend/
├── api/
│   ├── routes/          # FastAPI endpoints
│   ├── services/        # Business logic
│   │   ├── schema_discovery.py    # Auto-discover DB schemas
│   │   ├── query_engine.py        # Unified query processing
│   │   ├── document_processor.py  # Document ingestion
│   │   └── vector_store.py        # Semantic search
│   └── models/          # Pydantic schemas
└── tests/               # Unit tests
```

### Frontend Structure

```text
frontend/src/
├── components/
│   ├── AppLayout.tsx           # Main layout
│   └── contexts/              # React contexts
├── App.tsx                    # Root component
└── main.tsx                   # Entry point
```

## Features

✅ **Schema Discovery**: Automatically detects table structures and relationships  
✅ **Natural Language Queries**: Converts English to SQL and semantic search  
✅ **Document Processing**: Handles PDFs, Word docs, CSVs with intelligent chunking  
✅ **Caching**: TTL-based response caching for performance  
✅ **Multi-format Results**: Returns structured data and document excerpts  
✅ **Query History**: Tracks and caches previous queries  
✅ **LLM-powered SQL**: Uses Groq (Llama) to translate natural language to SQL  
✅ **Data Modification (DML)**: Natural language UPDATE/INSERT/DELETE with safety guards (no LIMIT on DML, affected_rows returned)

## Troubleshooting

- No module named 'psycopg2'
  - Cause: SQLAlchemy is attempting to use the old psycopg2 driver when your environment only has psycopg v3 installed (as specified in `requirements.txt`).
  - Fix: Use a connection string that explicitly selects psycopg v3: `postgresql+psycopg://user:password@host:5432/dbname`.
  - Optional: You could install `psycopg2-binary`, but psycopg2 may not support the newest Python versions promptly (e.g. 3.13). Prefer psycopg v3.


